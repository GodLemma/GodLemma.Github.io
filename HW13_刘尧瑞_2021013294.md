### 我们提供了一个qPCR数据集qPCR_data.csv，第1列为sample id，第2-12列为特征(11个基因的表达量)，第13列为样本标签(负例为健康人:NC,正例为肝癌病人:HCC)。请大家提交R语言代码，必要的文字解释和ROC曲线。

**code:**
```R
#数据预处理
table <- read.csv("C:\\Users\\86135\\Downloads\\qPCR_data.csv")
y <- table$label
x <- table[,2:12]
x <- apply(x,2,as.numeric)
feature.mean <- colMeans(x,na.rm = T)
# fill missing value with average value of this feature 
x[is.na(x)] <- matrix(rep(feature.mean,each=length(y)), nrow=length(y))[is.na(x)]
# Z score scaling
x <- scale(x,center = TRUE,scale = TRUE)
table[,2:12] <- x

#用PCA对数据进行可视化
res.pca <- PCA(x, scale.unit = TRUE, ncp = 2, graph = FALSE)
# 提取主成分得分
df.scores <- data.frame(PC1 = res.pca$ind$coord[,1], PC2 = res.pca$ind$coord[,2], row.names = rownames(x))
# 将得分与原始变量进行合并
df.combined <- cbind(df.scores, x)
# 使用ggplot2绘制散点图
ggplot(df.combined, aes(x=PC1, y=PC2)) +
  geom_point(size=3) +
  theme_minimal() +
  labs(x="PC1 (% Variance)", y="PC2 (% Variance)") +
  scale_color_viridis_d()

#数据集划分
set.seed(666) # 固定random seed保证结果可重复
# 80% data for training, 20% for performance evaluation
train.indices <- createDataPartition(y,p=0.8,times = 1,list=T)$Resample1
x.train <- x[train.indices,]
x.test <- x[ -train.indices,]
y.train <- y[train.indices]
y.test <- y[ -train.indices]
y.train <- as.factor(y.train)
y.test <- as.factor(y.test)

#特征选择
rfFuncs$summary <- twoClassSummary 
rfectrl <- rfeControl(functions=rfFuncs,
                      verbose = TRUE,
                      method="boot",number=10)
rfe.results <- rfe(x.train,y.train, 
                   sizes=2:12, 
                   rfeControl=rfectrl,
                   metric = "ROC")
selected.features <- predictors(rfe.results)
selected.features


#模型和调参拟合
params.grid <- expand.grid(alpha = c(0,0.5,1),lambda = c(0,0.01,0.1,1))
tr.ctrl <- trainControl(method="cv",
                        number = 5,
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE)
cv.fitted <- train(x.train[,predictors(rfe.results)],y.train,
                   method="glmnet",
                   family="binomial",
                   metric = "ROC",
                   tuneGrid = params.grid,
                   preProcess = NULL,
                   trControl = tr.ctrl )


#评估模型性能
predicted_probs <- predict(cv.fitted, x.test, type = 'prob')
roc.curve <- roc(y.test,y.test.pred.prob[,2])
plot(roc.curve,print.auc=T)
```

PCA可视化图：

![Rplot](https://github.com/GodLemma/Bioinformatics/assets/162097106/3dd21c34-9895-4d0b-8492-73dabaa0ad70)

ROC曲线：

![AUCOC](https://github.com/GodLemma/Bioinformatics/assets/162097106/c3599a8e-2ac9-48ea-b4fd-87f2cb7317bd)

### 8.2 请大家查阅资料，回答以下两个关于随机森林的问题：1）随机森林中树的数量是不是一个需要通过交叉验证调整的超参数?为什么?2）请问什么是随机森林的out-of-bag (OOB) error?它和bootstrapping有什么关系?

Answer：

1）不需要。因为随机森林算法的泛化误差会几乎处处收敛，因此整体来说会随着树的增加，模型的准确度也会增加。

2）由于随机森林是一种Bootstrapping方法，所以它每次选择训练集时是有放回的选择，计算概率可以发现这种有放回选取会使得大概三分之一的样本没有被选到，这部分样本称为袋外数据（out-of-bag data），由于袋外数据没有参与训练，可以用它们来做交叉验证检验模型的泛化能力。由于每一颗树都能计算出一个袋外数据的误差，用他们的均值作为该随机森林模型的OOB error.
